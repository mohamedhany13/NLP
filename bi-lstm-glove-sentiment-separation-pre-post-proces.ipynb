{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import sys, os, re, csv, codecs, numpy as np, pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from tensorflow.keras import *\n",
    "from tensorflow.keras.layers import *\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.layers import Dense, Input, LSTM, Embedding, Dropout, Activation\n",
    "from keras.layers import Bidirectional, GlobalMaxPool1D\n",
    "from keras.models import Model\n",
    "from keras import initializers, regularizers, constraints, optimizers, layers,losses\n",
    "from keras.utils import to_categorical\n",
    "import keras.backend as kb\n",
    "from nltk.corpus import words\n",
    "import random as rand\n",
    "import spacy\n",
    "import re\n",
    "from tqdm import tqdm\n",
    "import scipy.stats as ss\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv('../input/tweet-sentiment-extraction/train.csv')\n",
    "test = pd.read_csv('../input/tweet-sentiment-extraction/test.csv')\n",
    "\n",
    "#test data frame doens't have a selected text column, so it's created to be later filled\n",
    "test[\"selected_text\"]=\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>textID</th>\n",
       "      <th>text</th>\n",
       "      <th>selected_text</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>15304</th>\n",
       "      <td>2d6e96cb85</td>\n",
       "      <td>No more Wiffleball..  ****.</td>\n",
       "      <td>****.</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5118</th>\n",
       "      <td>b2ca6221e6</td>\n",
       "      <td>Doing really well! I will stay here as long a...</td>\n",
       "      <td>Doing really well!</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9057</th>\n",
       "      <td>f40b6c405c</td>\n",
       "      <td>doesn`t wanna get dressed up and be an adult t...</td>\n",
       "      <td>doesn`t wanna get dressed up an</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>873</th>\n",
       "      <td>2554631fd6</td>\n",
       "      <td>_beery Yeah little rough this morning but more...</td>\n",
       "      <td>rough</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18676</th>\n",
       "      <td>257010ac59</td>\n",
       "      <td>Work around the house  boo</td>\n",
       "      <td>boo</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           textID                                               text  \\\n",
       "15304  2d6e96cb85                        No more Wiffleball..  ****.   \n",
       "5118   b2ca6221e6   Doing really well! I will stay here as long a...   \n",
       "9057   f40b6c405c  doesn`t wanna get dressed up and be an adult t...   \n",
       "873    2554631fd6  _beery Yeah little rough this morning but more...   \n",
       "18676  257010ac59                         Work around the house  boo   \n",
       "\n",
       "                         selected_text sentiment  \n",
       "15304                            ****.  negative  \n",
       "5118                Doing really well!  positive  \n",
       "9057   doesn`t wanna get dressed up an  negative  \n",
       "873                              rough  negative  \n",
       "18676                              boo  negative  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# We will do some EDA to get further insight about our data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ratio of each sentiment relative to total number of tweets:\n",
      "train data:\n",
      " neutral     0.404570\n",
      "positive    0.312288\n",
      "negative    0.283141\n",
      "Name: sentiment, dtype: float64\n",
      "test data:\n",
      " neutral     0.404641\n",
      "positive    0.312111\n",
      "negative    0.283248\n",
      "Name: sentiment, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(\"ratio of each sentiment relative to total number of tweets:\")\n",
    "train_relative_count=train.sentiment.value_counts(normalize=True)\n",
    "test_relative_count=test.sentiment.value_counts(normalize=True)\n",
    "print(\"train data:\\n\",train_relative_count)\n",
    "print(\"test data:\\n\",test_relative_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_jaccard(sentiment_data):\n",
    "    jaccard_list=[]\n",
    "    for i in sentiment_data.index:\n",
    "        text_set=set(sentiment_data.text[i].split())\n",
    "        selected_set=set(sentiment_data.selected_text[i].split())\n",
    "        intersection=text_set.intersection(selected_set)\n",
    "        jaccard= float(len(intersection)/(len(text_set)+len(selected_set)-len(intersection)))\n",
    "        jaccard_list.append(jaccard)\n",
    "    \n",
    "    average_jaccard=sum(jaccard_list)/len(jaccard_list)\n",
    "    return average_jaccard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentiment_split(data):\n",
    "    \n",
    "    data_copy=data.copy()\n",
    "    \n",
    "    neutral_tweets=data_copy[data_copy[\"sentiment\"]==\"neutral\"]\n",
    "    neutral_tweets=neutral_tweets.copy()\n",
    "    \n",
    "    positive_tweets=data_copy[data_copy.sentiment==\"positive\"]\n",
    "    positive_tweets=positive_tweets.copy()\n",
    "    \n",
    "    negative_tweets=data_copy[data_copy.sentiment==\"negative\"]\n",
    "    negative_tweets=negative_tweets.copy()\n",
    "\n",
    "    return neutral_tweets,positive_tweets,negative_tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "neutral     0.404549\n",
      "positive    0.312300\n",
      "negative    0.283151\n",
      "Name: sentiment, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "train_copy=train.copy()\n",
    "train_copy.dropna(axis=0, how=\"any\", inplace=True)\n",
    "train_copy.reset_index(inplace=True)\n",
    "print(train_copy.sentiment.value_counts(normalize=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# We will check if there are rows in which selected text is not part of the text and try to fix it (we will correct misspelled words in selected text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_word(word): \n",
    "    return [char for char in word] \n",
    "\n",
    "def get_jaccard_word(word1,word2):\n",
    "    word1_char=split_word(word1)\n",
    "    word2_char=split_word(word2)\n",
    "    set1=set(word1_char)\n",
    "    set2=set(word2_char)\n",
    "    intersection=set1.intersection(set2)\n",
    "    jaccard_score=len(intersection)/(len(set1)+len(set2)-len(intersection))\n",
    "    return jaccard_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_index_word_in_string(word,text_split):\n",
    "    word_index=[]\n",
    "    for i in range(len(text_split)):\n",
    "        split_word=re.sub(\" \",\"\",text_split[i])\n",
    "        if word==split_word:\n",
    "            word_index.append(i)\n",
    "    if len(word_index)==0:\n",
    "        word_index=-1\n",
    "    return word_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/27480 [00:00<?, ?it/s]/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:30: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "100%|██████████| 27480/27480 [00:16<00:00, 1653.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of rows in which mismatch between text and selected text was found:  2905\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "selected_text_mismatch=0\n",
    "mismatched_rows=[]\n",
    "for i in tqdm(train_copy.index):\n",
    "    mismatch=0\n",
    "    text_split=train_copy.text[i].split()\n",
    "    selected_split=train_copy.selected_text[i].split()    \n",
    "    correct_selected_text=[]\n",
    "    for word in selected_split:  \n",
    "        \n",
    "        word_match=get_index_word_in_string(word,text_split)\n",
    "#        match=0\n",
    "#        for j in range(len(text_split)):\n",
    "#            if word==text_split[j]:\n",
    "#                match=1\n",
    "#                break\n",
    "                \n",
    "        if word_match!=-1:\n",
    "            correct_selected_text.append(word)\n",
    "            continue\n",
    "        if word_match==-1:\n",
    "            mismatch=1\n",
    "            jaccard_scores=np.zeros(len(text_split))\n",
    "            for k in range(len(text_split)):\n",
    "                jaccard_scores[k]=get_jaccard_word(word,text_split[k])\n",
    "                \n",
    "            correct_word_index=np.argmax(jaccard_scores)\n",
    "            correct_word=text_split[correct_word_index]\n",
    "            correct_selected_text.append(correct_word)\n",
    "            \n",
    "    train_copy.selected_text[i]=\" \".join(correct_selected_text)\n",
    "    if mismatch==1:\n",
    "        selected_text_mismatch=selected_text_mismatch+1\n",
    "        mismatched_rows.append(i)\n",
    "\n",
    "print(\"number of rows in which mismatch between text and selected text was found: \",selected_text_mismatch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "jaccard score between text and selected text:\n",
      "neutral sentiments jaccard score:  0.9814787965741442\n",
      "positive sentiments jaccard score:  0.33271248271474424\n",
      "negative sentiments jaccard score:  0.3561183376209603\n"
     ]
    }
   ],
   "source": [
    "neutral_tweets,positive_tweets,negative_tweets=sentiment_split(train_copy)\n",
    "\n",
    "print(\"jaccard score between text and selected text:\")\n",
    "#sentiment jaccard score\n",
    "neutral_jaccard=get_jaccard(neutral_tweets)\n",
    "print(\"neutral sentiments jaccard score: \",neutral_jaccard)\n",
    "positive_jaccard=get_jaccard(positive_tweets)\n",
    "print(\"positive sentiments jaccard score: \",positive_jaccard)\n",
    "negative_jaccard=get_jaccard(negative_tweets)\n",
    "print(\"negative sentiments jaccard score: \",negative_jaccard)"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# neutral tweets have a jaccard score of approximately 1, so they don't really need a model to train. We could just use the text as the selected text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#split test data\n",
    "neutral_tweets_test,positive_tweets_test,negative_tweets_test=sentiment_split(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# we will remove any special characters in our data to be able to better train it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_special_characters(str1):\n",
    "    '''\n",
    "    Takes a string, removes(substituted by \"\") all special characters and URLS and returns it.\n",
    "    '''\n",
    "    url_pattern = 'http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|[!*\\(\\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+'\n",
    "    # Remove URLs with re.sub(pattern, replacement, string)\n",
    "    cache = re.sub(url_pattern, ' ', str(str1))  \n",
    "    # Removing spec. characters\n",
    "    \n",
    "    character_pattern = '\\||\\,|\\;|\\.|\\:|\\#|\\*|\\~|\\+|\\-|\\/|\\_|\\?|\\!|\\\"|\\'|\\`|\\(|\\)|\\=|\\&|\\%|\\$|\\§' \n",
    "    split_text=str(cache).split()\n",
    "    filtered_text=[]\n",
    "    for i in range(len(split_text)):\n",
    "        contains_alphabet=re.search('[a-zA-Z]', split_text[i])\n",
    "        # doing this step keeps separate symbols\n",
    "        if contains_alphabet is not None:\n",
    "            filtered_text.append(str(re.sub(character_pattern, ' ', split_text[i])))\n",
    "        else:\n",
    "            filtered_text.append(split_text[i])\n",
    "    \n",
    "    filtered_text=\" \".join(filtered_text)\n",
    "    \n",
    "    #doing this step removes spaces from words\n",
    "    output_text=filtered_text.split()\n",
    "    for i in range(len(output_text)):\n",
    "        output_text[i]=re.sub(\" \",\"\",output_text[i])\n",
    "        \n",
    "    output=\" \".join(output_text)\n",
    "#    return re.sub(character_pattern, ' ', str(cache))\n",
    "    return str(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_empty_string(data):\n",
    "    text_counter=0\n",
    "    selected_text_counter=0\n",
    "    for i in data.index:\n",
    "        if \"clean_text\" in data:\n",
    "            if len(data.clean_text[i].split())==0:\n",
    "                text_counter=text_counter+1\n",
    "        if \"clean_selected\" in data:\n",
    "            if len(data.clean_selected[i].split())==0:\n",
    "                selected_text_counter=selected_text_counter+1   \n",
    "                \n",
    "    print(\"null clean text: \", text_counter)\n",
    "    if \"clean_selected\" in data:\n",
    "        print(\"null selected clean text: \", selected_text_counter)\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "positive tweets:\n",
      "null clean text:  0\n",
      "null selected clean text:  0\n",
      "negative tweets:\n",
      "null clean text:  0\n",
      "null selected clean text:  0\n",
      "test positive tweets:\n",
      "null clean text:  0\n",
      "test negative tweets:\n",
      "null clean text:  0\n"
     ]
    }
   ],
   "source": [
    "positive_tweets['clean_text'] = positive_tweets['text'].str.lower().apply(remove_special_characters)\n",
    "positive_tweets['clean_selected'] = positive_tweets['selected_text'].str.lower().apply(remove_special_characters)\n",
    "print(\"positive tweets:\")\n",
    "check_empty_string(positive_tweets)\n",
    "\n",
    "negative_tweets['clean_text'] = negative_tweets['text'].str.lower().apply(remove_special_characters)\n",
    "negative_tweets['clean_selected'] = negative_tweets['selected_text'].str.lower().apply(remove_special_characters)\n",
    "print(\"negative tweets:\")\n",
    "check_empty_string(negative_tweets)\n",
    "\n",
    "positive_tweets_test['clean_text'] = positive_tweets_test['text'].str.lower().apply(remove_special_characters)\n",
    "print(\"test positive tweets:\")\n",
    "check_empty_string(positive_tweets_test)\n",
    "\n",
    "negative_tweets_test['clean_text'] = negative_tweets_test['text'].str.lower().apply(remove_special_characters)\n",
    "print(\"test negative tweets:\")\n",
    "check_empty_string(negative_tweets_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# In this next step, we plot histograms for the tweets in order to decide the value of the length of text input to the neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "totalNumWords = [len(positive_tweets['clean_text'][index].split()) for index in positive_tweets.index]\n",
    "plt.hist(totalNumWords,bins = np.arange(0,35,1))\n",
    "plt.title('positive tweets')\n",
    "plt.xlabel('length of tweet')\n",
    "plt.ylabel('number of tweets')\n",
    "plt.show()\n",
    "\n",
    "totalNumWords = [len(negative_tweets['clean_text'][index].split()) for index in negative_tweets.index]\n",
    "plt.hist(totalNumWords,bins = np.arange(0,35,1))\n",
    "plt.title('negative tweets')\n",
    "plt.xlabel('length of tweet')\n",
    "plt.ylabel('number of tweets')\n",
    "plt.show()\n",
    "\n",
    "totalNumWords = [len(positive_tweets_test['clean_text'][index].split()) for index in positive_tweets_test.index]\n",
    "plt.hist(totalNumWords,bins = np.arange(0,35,1))\n",
    "plt.title('test positive tweets')\n",
    "plt.xlabel('length of tweet')\n",
    "plt.ylabel('number of tweets')\n",
    "plt.show()\n",
    "\n",
    "totalNumWords = [len(negative_tweets_test['clean_text'][index].split()) for index in negative_tweets_test.index]\n",
    "plt.hist(totalNumWords,bins = np.arange(0,35,1))\n",
    "plt.title('test negative tweets')\n",
    "plt.xlabel('length of tweet')\n",
    "plt.ylabel('number of tweets')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# instead of using a dictionary for nltk or spacy, we used the text from the training set and test set to make the dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 34830/34830 [00:01<00:00, 28157.94it/s]\n"
     ]
    }
   ],
   "source": [
    "t1=pd.DataFrame({'A': positive_tweets.clean_text})\n",
    "t2=pd.DataFrame({'A': positive_tweets.clean_selected})\n",
    "\n",
    "t3=pd.DataFrame({'A': negative_tweets.clean_text})\n",
    "t4=pd.DataFrame({'A': negative_tweets.clean_selected})\n",
    "\n",
    "t5=pd.DataFrame({'A': positive_tweets_test.clean_text})\n",
    "t6=pd.DataFrame({'A': negative_tweets_test.clean_text})\n",
    "\n",
    "all_text_tokens=pd.concat([t1,t2,t3,t4,t5,t6],axis=0)\n",
    "all_text_tokens.reset_index(inplace=True)\n",
    "\n",
    "tokens_set=set()\n",
    "for i in tqdm(all_text_tokens.index):\n",
    "    tokens_set.update(all_text_tokens.A[i].split())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# converting text into numerical tokens\n",
    "\n",
    "max_word_dict = len(tokens_set)\n",
    "\n",
    "tokenizer = Tokenizer(num_words=max_word_dict, lower=True, oov_token=\"<UKN>\",filters='')\n",
    "tokenizer.fit_on_texts(tokens_set)\n",
    "\n",
    "vocab_size=len(tokenizer.word_index)+1\n",
    "\n",
    "positive_tweets_train = tokenizer.texts_to_sequences(positive_tweets['clean_text'])\n",
    "positive_selected_tokenize=tokenizer.texts_to_sequences(positive_tweets['clean_selected'])\n",
    "\n",
    "negative_tweets_train = tokenizer.texts_to_sequences(negative_tweets['clean_text'])\n",
    "negative_selected_tokenize=tokenizer.texts_to_sequences(negative_tweets['clean_selected'])\n",
    "\n",
    "positive_test = tokenizer.texts_to_sequences(positive_tweets_test['clean_text'])\n",
    "negative_test = tokenizer.texts_to_sequences(negative_tweets_test['clean_text'])"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# The following function is used to create an array of 0's & 1's as the output of the NN. The 1's are placed in the indices of the words, which make up the selected text, in the input tweet "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_y_train(tokenized_selected_text_train,x_train):\n",
    "    y_train=[]\n",
    "    empty_selected=[]\n",
    "    for i in range(len(x_train)):\n",
    "        selected_text_array=np.array(tokenized_selected_text_train[i])\n",
    "        if len(selected_text_array)==0:\n",
    "            #print(\"empty selected text in index: \",i)\n",
    "            empty_selected.append(i)\n",
    "            selected_text=np.zeros(max_tweet_length)\n",
    "            y_train.append(selected_text)\n",
    "            continue\n",
    "        first_word_indices=np.where(x_train[i]==selected_text_array[0])\n",
    "        first_word_indices=np.array(first_word_indices)\n",
    "        for j in first_word_indices[0]:\n",
    "            start_index=j\n",
    "            end_index=j+np.max(np.shape(selected_text_array))-1\n",
    "            x_train_sub_array=x_train[i][start_index:end_index+1]\n",
    "            if np.array_equal(x_train_sub_array,selected_text_array):\n",
    "                break\n",
    "        selected_text=np.zeros(max_tweet_length)\n",
    "        selected_text[start_index:end_index+1]=1\n",
    "        y_train.append(selected_text)\n",
    "    y_train=np.array(y_train) \n",
    "    print(\"number of empty selected text: \",len(empty_selected))\n",
    "    return y_train,empty_selected"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# The following are all the hyperparameters in the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# length of input to NN\n",
    "max_tweet_length=34\n",
    "\n",
    "# embedding vector length of the embedding layer (should match the used vector length in the pretrained network)\n",
    "embedding_vector_length=300\n",
    "\n",
    "# number of units in LSTM layer \n",
    "HIDDEN_DIM=512\n",
    "\n",
    "# LSTM L2 regularization parameter\n",
    "lstm_l2=0.03\n",
    "\n",
    "# dense layers number of units\n",
    "dense_units=64\n",
    "\n",
    "# dropout value\n",
    "dropout_value=0.3\n",
    "\n",
    "# loss used in cost function   (choose either \"binary_crossentropy\" or losses.SparseCategoricalCrossentropy())\n",
    "model_loss=\"binary_crossentropy\"\n",
    "\n",
    "# batch size\n",
    "batch_size=32\n",
    "\n",
    "# number of epochs\n",
    "epochs=34\n",
    "\n",
    "# validation split of training data\n",
    "validation_split=0.1\n",
    "\n",
    "#learning metric      (choose either \"accuracy\" of \"binary_accuracy\")\n",
    "learning_metric=\"binary_accuracy\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of empty selected text:  0\n",
      "number of empty selected text:  0\n"
     ]
    }
   ],
   "source": [
    "positive_x_train = pad_sequences(positive_tweets_train, maxlen=max_tweet_length)\n",
    "negative_x_train = pad_sequences(negative_tweets_train, maxlen=max_tweet_length)\n",
    "\n",
    "positive_x_test = pad_sequences(positive_test, maxlen=max_tweet_length)\n",
    "negative_x_test = pad_sequences(negative_test, maxlen=max_tweet_length)\n",
    "\n",
    "positive_y_train,positive_selected_empty=get_y_train(positive_selected_tokenize,positive_x_train)\n",
    "negative_y_train,negative_selected_empty=get_y_train(negative_selected_tokenize,negative_x_train)\n",
    "\n",
    "#positive_y_train=pad_sequences(positive_selected_tokenize, maxlen=max_tweet_length)\n",
    "#negative_y_train=pad_sequences(negative_selected_tokenize, maxlen=max_tweet_length)"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# We used a pre-trained network for the word embedding of our text. GloVe for twitter is used here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_glove():\n",
    "    tqdm.pandas()\n",
    "    f = open('../input/glove840b300dtxt/glove.840B.300d.txt')\n",
    "    embedding_dict = {}\n",
    "    for line in tqdm(f):\n",
    "        word_emb=line.split(' ')\n",
    "        word=word_emb[0]\n",
    "        embedding_vector=np.array(word_emb[1:],dtype = 'float32')\n",
    "        embedding_dict[word]=embedding_vector\n",
    "    \n",
    "    f.close()\n",
    "    return embedding_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_glove(tokenizer,embedding_dict,embedding_vector_length):\n",
    "    \n",
    "    vocab_size=len(tokenizer.word_index)+1\n",
    "    \n",
    "    all_embs = np.stack(embedding_dict.values())\n",
    "    emb_mean,emb_std = all_embs.mean(), all_embs.std()\n",
    "    embedding_matrix = np.random.normal(emb_mean, emb_std, (vocab_size, embedding_vector_length))\n",
    "    \n",
    "    out_of_dict=[]\n",
    "    \n",
    "    for word,value in tqdm(tokenizer.word_index.items()):\n",
    "        embedding_vector=embedding_dict.get(word)\n",
    "        if embedding_vector is not None:\n",
    "            embedding_matrix[value]=embedding_vector\n",
    "        else:\n",
    "            out_of_dict.append(word)     \n",
    "                \n",
    "    print(\"number of words not in embedding dictionary: \", len(out_of_dict))        \n",
    "    return embedding_matrix,out_of_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/tqdm/std.py:666: FutureWarning: The Panel class is removed from pandas. Accessing it from the top-level namespace will also be removed in the next version\n",
      "  from pandas import Panel\n",
      "2196018it [05:30, 6643.34it/s]\n",
      "/opt/conda/lib/python3.7/site-packages/IPython/core/interactiveshell.py:3331: FutureWarning: arrays to stack must be passed as a \"sequence\" type such as list or tuple. Support for non-sequence iterables such as generators is deprecated as of NumPy 1.16 and will raise an error in the future.\n",
      "  exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "100%|██████████| 19823/19823 [00:00<00:00, 278299.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of words not in embedding dictionary:  2672\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "embedding_dict=load_glove()\n",
    "embedding_matrix,out_of_embedding_dict=fit_glove(tokenizer,embedding_dict,embedding_vector_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['<UKN>', 'g1986', 'day<3', 'muahahahhahaha', 'darnitt', 'accela', 'ccrying', 'soberana', '_04071991', '(?)', 'fkc', 'dunners', '3..', '<3criminy', 'booklife', 'bradies', 'suuuks', 'ï¿½80', 'ouuuuuuuuuchhhhhhhh', 'mtfbwy', 'binstruct', 'chilliin', '1thing', 'yuuum', 'fitzcarraldo', 'saaaaaaid', 'grtsat', 'cnaterbury', 'nylana', 'oowwwww', 'rainging', 'tifanny', 'mygrilled', \"...'\", 'twitster', 'icurve', 'walwal', 'amazeeeeeee', 'offiacial', 'mayjah', 'mammyy', '((((((((((((((((((', 'ohay', '}:', '50%', 'cooolooorss', 'youregreat', 'sarrah', 'pachad', 'myweawkness', 'heelllll']\n"
     ]
    }
   ],
   "source": [
    "print(out_of_embedding_dict[0:51])"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Next is the model architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 34)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding (Embedding)           (None, 34, 300)      5947200     input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional (Bidirectional)   (None, 34, 1024)     3330048     embedding[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed (TimeDistribut (None, 34, 64)       65600       bidirectional[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_3 (TimeDistrib (None, 34, 64)       0           time_distributed[0][0]           \n",
      "                                                                 time_distributed_1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_1 (TimeDistrib (None, 34, 64)       4160        time_distributed_3[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_4 (TimeDistrib (None, 34, 1)        65          time_distributed_3[1][0]         \n",
      "==================================================================================================\n",
      "Total params: 9,347,073\n",
      "Trainable params: 3,399,873\n",
      "Non-trainable params: 5,947,200\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "\n",
    "    \n",
    "inputs_n = Input(shape=(max_tweet_length,), dtype='int32')\n",
    "\n",
    "embedding_layer_n = Embedding(vocab_size, embedding_vector_length, weights=[embedding_matrix],trainable=False)\n",
    "encoder_LSTM_n = Bidirectional(LSTM(HIDDEN_DIM,return_sequences=True,kernel_regularizer=regularizers.l2(lstm_l2)))\n",
    "dense_layer_relu_n1 = TimeDistributed(Dense(dense_units, activation='relu'))\n",
    "dense_layer_relu_n2 = TimeDistributed(Dense(dense_units, activation='relu'))\n",
    "dense_layer_sigmoid_n = TimeDistributed(Dense(64, activation='sigmoid'))\n",
    "Drop_n = TimeDistributed(Dropout(dropout_value))\n",
    "dense_layer_n = TimeDistributed(Dense(1, activation='sigmoid'))\n",
    "\n",
    "encoder_embedding_n = embedding_layer_n(inputs_n)\n",
    "Encoded_seq_n = encoder_LSTM_n(encoder_embedding_n)\n",
    "outputs_n = Drop_n(dense_layer_relu_n1(Encoded_seq_n))\n",
    "outputs_n = Drop_n(dense_layer_relu_n2(outputs_n))\n",
    "#outputs_n= Drop_n(dense_layer_sigmoid_n(outputs_n))\n",
    "outputs_n = dense_layer_n(outputs_n)\n",
    "\n",
    "negative_model = Model(inputs=inputs_n, outputs=outputs_n)  \n",
    "negative_model.compile(optimizer='Adam', loss=model_loss,metrics=[learning_metric])\n",
    "negative_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_2 (InputLayer)            [(None, 34)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_1 (Embedding)         (None, 34, 300)      5947200     input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_1 (Bidirectional) (None, 34, 1024)     3330048     embedding_1[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_5 (TimeDistrib (None, 34, 64)       65600       bidirectional_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_8 (TimeDistrib (None, 34, 64)       0           time_distributed_5[0][0]         \n",
      "                                                                 time_distributed_6[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_6 (TimeDistrib (None, 34, 64)       4160        time_distributed_8[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_9 (TimeDistrib (None, 34, 1)        65          time_distributed_8[1][0]         \n",
      "==================================================================================================\n",
      "Total params: 9,347,073\n",
      "Trainable params: 3,399,873\n",
      "Non-trainable params: 5,947,200\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "inputs_p = Input(shape=(max_tweet_length,), dtype='int32')\n",
    "\n",
    "embedding_layer_p = Embedding(vocab_size, embedding_vector_length, weights=[embedding_matrix],trainable=False)\n",
    "encoder_LSTM_p = Bidirectional(LSTM(HIDDEN_DIM,return_sequences=True,kernel_regularizer=regularizers.l2(lstm_l2)))\n",
    "dense_layer_relu_p1 = TimeDistributed(Dense(dense_units, activation='relu'))\n",
    "dense_layer_relu_p2 = TimeDistributed(Dense(dense_units, activation='relu'))\n",
    "dense_layer_sigmoid_p = TimeDistributed(Dense(64, activation='sigmoid'))\n",
    "Drop_p = TimeDistributed(Dropout(dropout_value))\n",
    "dense_layer_p = TimeDistributed(Dense(1, activation='sigmoid'))\n",
    "\n",
    "encoder_embedding_p = embedding_layer_p(inputs_p)\n",
    "Encoded_seq_p = encoder_LSTM_p(encoder_embedding_p)\n",
    "outputs_p = Drop_p(dense_layer_relu_p1(Encoded_seq_p))\n",
    "outputs_p = Drop_p(dense_layer_relu_p2(outputs_p))\n",
    "#outputs_p= Drop_p(dense_layer_sigmoid_p(outputs_p))\n",
    "outputs_p = dense_layer_p(outputs_p)\n",
    "\n",
    "positive_model = Model(inputs=inputs_p, outputs=outputs_p)  \n",
    "positive_model.compile(optimizer='Adam', loss=model_loss,metrics=[learning_metric])\n",
    "positive_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "if model_loss != \"binary_crossentropy\":\n",
    "    y_train=np.reshape(negative_y_train,np.product(np.shape(negative_y_train)))\n",
    "    print(np.shape(y_train))\n",
    "    negative_y_train=y_train\n",
    "    y_train=np.reshape(positive_y_train,np.product(np.shape(positive_y_train)))\n",
    "    positive_y_train=y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/34\n",
      "242/242 [==============================] - 103s 427ms/step - loss: 2.1274 - binary_accuracy: 0.8952 - val_loss: 0.2317 - val_binary_accuracy: 0.8976\n",
      "Epoch 2/34\n",
      "242/242 [==============================] - 100s 412ms/step - loss: 0.2264 - binary_accuracy: 0.9050 - val_loss: 0.2227 - val_binary_accuracy: 0.9018\n",
      "Epoch 3/34\n",
      "242/242 [==============================] - 100s 414ms/step - loss: 0.2194 - binary_accuracy: 0.9069 - val_loss: 0.2205 - val_binary_accuracy: 0.9061\n",
      "Epoch 4/34\n",
      "242/242 [==============================] - 103s 424ms/step - loss: 0.2171 - binary_accuracy: 0.9074 - val_loss: 0.2155 - val_binary_accuracy: 0.9072\n",
      "Epoch 5/34\n",
      "242/242 [==============================] - 103s 427ms/step - loss: 0.2145 - binary_accuracy: 0.9088 - val_loss: 0.2105 - val_binary_accuracy: 0.9084\n",
      "Epoch 6/34\n",
      "242/242 [==============================] - 99s 411ms/step - loss: 0.2111 - binary_accuracy: 0.9093 - val_loss: 0.2138 - val_binary_accuracy: 0.9071\n",
      "Epoch 7/34\n",
      "242/242 [==============================] - 100s 414ms/step - loss: 0.2108 - binary_accuracy: 0.9098 - val_loss: 0.2112 - val_binary_accuracy: 0.9094\n",
      "Epoch 8/34\n",
      "242/242 [==============================] - 100s 413ms/step - loss: 0.2264 - binary_accuracy: 0.9100 - val_loss: 0.3020 - val_binary_accuracy: 0.9093\n",
      "Epoch 9/34\n",
      "242/242 [==============================] - 102s 420ms/step - loss: 0.2141 - binary_accuracy: 0.9104 - val_loss: 0.2080 - val_binary_accuracy: 0.9087\n",
      "Epoch 10/34\n",
      "242/242 [==============================] - 102s 421ms/step - loss: 0.2055 - binary_accuracy: 0.9112 - val_loss: 0.2074 - val_binary_accuracy: 0.9093\n",
      "Epoch 11/34\n",
      "242/242 [==============================] - 110s 455ms/step - loss: 0.2059 - binary_accuracy: 0.9113 - val_loss: 0.2075 - val_binary_accuracy: 0.9082\n",
      "Epoch 12/34\n",
      "242/242 [==============================] - 101s 417ms/step - loss: 0.2065 - binary_accuracy: 0.9114 - val_loss: 0.2116 - val_binary_accuracy: 0.9029\n",
      "Epoch 13/34\n",
      "242/242 [==============================] - 99s 408ms/step - loss: 0.2054 - binary_accuracy: 0.9117 - val_loss: 0.2040 - val_binary_accuracy: 0.9114\n",
      "Epoch 14/34\n",
      "242/242 [==============================] - 97s 402ms/step - loss: 0.2045 - binary_accuracy: 0.9119 - val_loss: 0.2064 - val_binary_accuracy: 0.9090\n",
      "Epoch 15/34\n",
      "242/242 [==============================] - 98s 403ms/step - loss: 0.2048 - binary_accuracy: 0.9119 - val_loss: 0.2045 - val_binary_accuracy: 0.9099\n",
      "Epoch 16/34\n",
      "242/242 [==============================] - 99s 409ms/step - loss: 0.2040 - binary_accuracy: 0.9122 - val_loss: 0.2056 - val_binary_accuracy: 0.9099\n",
      "Epoch 17/34\n",
      "242/242 [==============================] - 97s 402ms/step - loss: 0.2048 - binary_accuracy: 0.9119 - val_loss: 0.2043 - val_binary_accuracy: 0.9101\n",
      "Epoch 18/34\n",
      "242/242 [==============================] - 108s 447ms/step - loss: 0.2047 - binary_accuracy: 0.9119 - val_loss: 0.2019 - val_binary_accuracy: 0.9104\n",
      "Epoch 19/34\n",
      "242/242 [==============================] - 98s 405ms/step - loss: 0.2043 - binary_accuracy: 0.9121 - val_loss: 0.2040 - val_binary_accuracy: 0.9111\n",
      "Epoch 20/34\n",
      "242/242 [==============================] - 96s 398ms/step - loss: 0.2049 - binary_accuracy: 0.9123 - val_loss: 0.2077 - val_binary_accuracy: 0.9107\n",
      "Epoch 21/34\n",
      "242/242 [==============================] - 96s 396ms/step - loss: 0.2031 - binary_accuracy: 0.9127 - val_loss: 0.2058 - val_binary_accuracy: 0.9111\n",
      "Epoch 22/34\n",
      "242/242 [==============================] - 98s 403ms/step - loss: 0.2042 - binary_accuracy: 0.9125 - val_loss: 0.2036 - val_binary_accuracy: 0.9113\n",
      "Epoch 23/34\n",
      "242/242 [==============================] - 96s 395ms/step - loss: 0.2031 - binary_accuracy: 0.9125 - val_loss: 0.2016 - val_binary_accuracy: 0.9101\n",
      "Epoch 24/34\n",
      "242/242 [==============================] - 95s 392ms/step - loss: 0.2047 - binary_accuracy: 0.9124 - val_loss: 0.2102 - val_binary_accuracy: 0.9094\n",
      "Epoch 25/34\n",
      "242/242 [==============================] - 96s 396ms/step - loss: 0.2042 - binary_accuracy: 0.9124 - val_loss: 0.2030 - val_binary_accuracy: 0.9105\n",
      "Epoch 26/34\n",
      "242/242 [==============================] - 95s 394ms/step - loss: 0.2030 - binary_accuracy: 0.9127 - val_loss: 0.2037 - val_binary_accuracy: 0.9110\n",
      "Epoch 27/34\n",
      "242/242 [==============================] - 97s 400ms/step - loss: 0.2031 - binary_accuracy: 0.9133 - val_loss: 0.2040 - val_binary_accuracy: 0.9111\n",
      "Epoch 28/34\n",
      "242/242 [==============================] - 98s 407ms/step - loss: 0.2030 - binary_accuracy: 0.9123 - val_loss: 0.2019 - val_binary_accuracy: 0.9113\n",
      "Epoch 29/34\n",
      "242/242 [==============================] - 95s 394ms/step - loss: 0.2035 - binary_accuracy: 0.9129 - val_loss: 0.2053 - val_binary_accuracy: 0.9102\n",
      "Epoch 30/34\n",
      "242/242 [==============================] - 96s 399ms/step - loss: 0.2030 - binary_accuracy: 0.9130 - val_loss: 0.2046 - val_binary_accuracy: 0.9111\n",
      "Epoch 31/34\n",
      "242/242 [==============================] - 101s 418ms/step - loss: 0.2033 - binary_accuracy: 0.9130 - val_loss: 0.2034 - val_binary_accuracy: 0.9110\n",
      "Epoch 32/34\n",
      "242/242 [==============================] - 96s 398ms/step - loss: 0.2029 - binary_accuracy: 0.9126 - val_loss: 0.2084 - val_binary_accuracy: 0.9102\n",
      "Epoch 33/34\n",
      "242/242 [==============================] - 96s 398ms/step - loss: 0.2024 - binary_accuracy: 0.9131 - val_loss: 0.2041 - val_binary_accuracy: 0.9109\n",
      "Epoch 34/34\n",
      "242/242 [==============================] - 95s 394ms/step - loss: 0.2022 - binary_accuracy: 0.9131 - val_loss: 0.2047 - val_binary_accuracy: 0.9105\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f734c314e10>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## the inputs to the method fit() have to be arrays not lists\n",
    "positive_model.fit(positive_x_train,positive_y_train, batch_size=batch_size, epochs=epochs, validation_split=validation_split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/34\n",
      "219/219 [==============================] - 88s 400ms/step - loss: 2.3224 - binary_accuracy: 0.8781 - val_loss: 0.2561 - val_binary_accuracy: 0.8778\n",
      "Epoch 2/34\n",
      "219/219 [==============================] - 87s 398ms/step - loss: 0.2487 - binary_accuracy: 0.8868 - val_loss: 0.2485 - val_binary_accuracy: 0.8851\n",
      "Epoch 3/34\n",
      "219/219 [==============================] - 96s 437ms/step - loss: 0.2431 - binary_accuracy: 0.8900 - val_loss: 0.2441 - val_binary_accuracy: 0.8887\n",
      "Epoch 4/34\n",
      "219/219 [==============================] - 87s 396ms/step - loss: 0.2413 - binary_accuracy: 0.8911 - val_loss: 0.2371 - val_binary_accuracy: 0.8904\n",
      "Epoch 5/34\n",
      "219/219 [==============================] - 86s 391ms/step - loss: 0.2457 - binary_accuracy: 0.8918 - val_loss: 0.2437 - val_binary_accuracy: 0.8865\n",
      "Epoch 6/34\n",
      "219/219 [==============================] - 86s 391ms/step - loss: 0.2366 - binary_accuracy: 0.8929 - val_loss: 0.2443 - val_binary_accuracy: 0.8853\n",
      "Epoch 7/34\n",
      "219/219 [==============================] - 88s 400ms/step - loss: 0.2356 - binary_accuracy: 0.8933 - val_loss: 0.2385 - val_binary_accuracy: 0.8899\n",
      "Epoch 8/34\n",
      "219/219 [==============================] - 86s 392ms/step - loss: 0.2334 - binary_accuracy: 0.8941 - val_loss: 0.2373 - val_binary_accuracy: 0.8901\n",
      "Epoch 9/34\n",
      "219/219 [==============================] - 86s 392ms/step - loss: 0.2335 - binary_accuracy: 0.8946 - val_loss: 0.2348 - val_binary_accuracy: 0.8906\n",
      "Epoch 10/34\n",
      "219/219 [==============================] - 85s 389ms/step - loss: 0.2325 - binary_accuracy: 0.8946 - val_loss: 0.2334 - val_binary_accuracy: 0.8916\n",
      "Epoch 11/34\n",
      "219/219 [==============================] - 86s 393ms/step - loss: 0.2320 - binary_accuracy: 0.8952 - val_loss: 0.2384 - val_binary_accuracy: 0.8918\n",
      "Epoch 12/34\n",
      "219/219 [==============================] - 85s 389ms/step - loss: 0.2307 - binary_accuracy: 0.8959 - val_loss: 0.2358 - val_binary_accuracy: 0.8927\n",
      "Epoch 13/34\n",
      "219/219 [==============================] - 87s 397ms/step - loss: 0.2313 - binary_accuracy: 0.8960 - val_loss: 0.2329 - val_binary_accuracy: 0.8925\n",
      "Epoch 14/34\n",
      "219/219 [==============================] - 87s 398ms/step - loss: 0.2309 - binary_accuracy: 0.8969 - val_loss: 0.2363 - val_binary_accuracy: 0.8915\n",
      "Epoch 15/34\n",
      "219/219 [==============================] - 86s 392ms/step - loss: 0.2303 - binary_accuracy: 0.8971 - val_loss: 0.2314 - val_binary_accuracy: 0.8940\n",
      "Epoch 16/34\n",
      "219/219 [==============================] - 86s 394ms/step - loss: 0.2295 - binary_accuracy: 0.8978 - val_loss: 0.2288 - val_binary_accuracy: 0.8960\n",
      "Epoch 17/34\n",
      "219/219 [==============================] - 90s 411ms/step - loss: 0.2276 - binary_accuracy: 0.8986 - val_loss: 0.2290 - val_binary_accuracy: 0.8951\n",
      "Epoch 18/34\n",
      "219/219 [==============================] - 87s 398ms/step - loss: 0.2309 - binary_accuracy: 0.8984 - val_loss: 0.2318 - val_binary_accuracy: 0.8951\n",
      "Epoch 19/34\n",
      "219/219 [==============================] - 86s 391ms/step - loss: 0.2290 - binary_accuracy: 0.8990 - val_loss: 0.2285 - val_binary_accuracy: 0.8964\n",
      "Epoch 20/34\n",
      "219/219 [==============================] - 88s 401ms/step - loss: 0.2279 - binary_accuracy: 0.8998 - val_loss: 0.2386 - val_binary_accuracy: 0.8939\n",
      "Epoch 21/34\n",
      "219/219 [==============================] - 86s 391ms/step - loss: 0.2268 - binary_accuracy: 0.9004 - val_loss: 0.2359 - val_binary_accuracy: 0.8956\n",
      "Epoch 22/34\n",
      "219/219 [==============================] - 87s 398ms/step - loss: 0.2276 - binary_accuracy: 0.8997 - val_loss: 0.2271 - val_binary_accuracy: 0.8986\n",
      "Epoch 23/34\n",
      "219/219 [==============================] - 87s 396ms/step - loss: 0.2271 - binary_accuracy: 0.9005 - val_loss: 0.2279 - val_binary_accuracy: 0.8981\n",
      "Epoch 24/34\n",
      "219/219 [==============================] - 97s 441ms/step - loss: 0.2268 - binary_accuracy: 0.9005 - val_loss: 0.2282 - val_binary_accuracy: 0.8961\n",
      "Epoch 25/34\n",
      "219/219 [==============================] - 87s 395ms/step - loss: 0.2265 - binary_accuracy: 0.9003 - val_loss: 0.2316 - val_binary_accuracy: 0.8953\n",
      "Epoch 26/34\n",
      "219/219 [==============================] - 87s 398ms/step - loss: 0.2264 - binary_accuracy: 0.9010 - val_loss: 0.2266 - val_binary_accuracy: 0.8964\n",
      "Epoch 27/34\n",
      "219/219 [==============================] - 86s 394ms/step - loss: 0.2257 - binary_accuracy: 0.9011 - val_loss: 0.2304 - val_binary_accuracy: 0.8962\n",
      "Epoch 28/34\n",
      "219/219 [==============================] - 86s 391ms/step - loss: 0.2251 - binary_accuracy: 0.9013 - val_loss: 0.2252 - val_binary_accuracy: 0.8977\n",
      "Epoch 29/34\n",
      "219/219 [==============================] - 87s 399ms/step - loss: 0.2247 - binary_accuracy: 0.9013 - val_loss: 0.2296 - val_binary_accuracy: 0.8968\n",
      "Epoch 30/34\n",
      "219/219 [==============================] - 85s 389ms/step - loss: 0.2244 - binary_accuracy: 0.9016 - val_loss: 0.2349 - val_binary_accuracy: 0.8949\n",
      "Epoch 31/34\n",
      "219/219 [==============================] - 86s 391ms/step - loss: 0.2254 - binary_accuracy: 0.9015 - val_loss: 0.2291 - val_binary_accuracy: 0.8974\n",
      "Epoch 32/34\n",
      "219/219 [==============================] - 86s 392ms/step - loss: 0.2240 - binary_accuracy: 0.9018 - val_loss: 0.2311 - val_binary_accuracy: 0.8968\n",
      "Epoch 33/34\n",
      "219/219 [==============================] - 86s 394ms/step - loss: 0.2236 - binary_accuracy: 0.9022 - val_loss: 0.2282 - val_binary_accuracy: 0.8977\n",
      "Epoch 34/34\n",
      "219/219 [==============================] - 86s 393ms/step - loss: 0.2246 - binary_accuracy: 0.9017 - val_loss: 0.2279 - val_binary_accuracy: 0.8969\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f7320164650>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## the inputs to the method fit() have to be arrays not lists\n",
    "negative_model.fit(negative_x_train,negative_y_train, batch_size=batch_size, epochs=epochs, validation_split=validation_split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "negative_y_test=negative_model.predict(negative_x_train)\n",
    "negative_y_test=np.around(negative_y_test)\n",
    "\n",
    "positive_y_test=positive_model.predict(positive_x_train)\n",
    "positive_y_test=np.around(positive_y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 1. 1. 1. 1.]]\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 1. 1. 1.]\n"
     ]
    }
   ],
   "source": [
    "print(np.transpose(negative_y_test[2]))\n",
    "print(negative_y_train[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_pred_index_into_selected_text(x,y,tweets_data,tokenizer):\n",
    "    \n",
    "    reverse_tokenizer=dict(map(reversed,tokenizer.word_index.items()))\n",
    "    data_text_lower=[item.lower() for item in tweets_data.text]\n",
    "    \n",
    "    no_selected_text=0\n",
    "    for i in range(len(tweets_data)):\n",
    "        \n",
    "## debugging\n",
    "#        if i==7:\n",
    "#            print(\"index number\", i, \"has the error\")        \n",
    "#            return\n",
    "        \n",
    "        actual_selected_words=[]\n",
    "        \n",
    "        tweets_data_index=tweets_data.index[i]        \n",
    "        split_tweet=tweets_data.text[tweets_data_index].split()\n",
    "\n",
    "        #filtered_split_tweet=[]\n",
    "        \n",
    "        # doing it this way instead of doing it without split solves this example:\n",
    "        # (hello ... world), the \"...\" will be removed but it will still take an index 1 and world will take index 2\n",
    "        # if split was not used, world will now take index 1\n",
    "#        for j in range(len(split_tweet)):\n",
    "#            filtered_split_tweet.append(remove_special_characters(split_tweet[j].lower()))\n",
    "        \n",
    "        filtered_split_tweet=remove_special_characters(tweets_data.text[tweets_data_index].lower())\n",
    "        filtered_split_tweet=filtered_split_tweet.split()\n",
    "        \n",
    "        predicted_indices=np.where(y[i]==1)\n",
    "        if len(predicted_indices[0])==0:\n",
    "            tweets_data.selected_text[tweets_data_index]=\"\"\n",
    "            #print(\"no selected text for tweet in row: \",tweets_data_index, \"index number: \",i)\n",
    "            no_selected_text=no_selected_text+1\n",
    "            continue\n",
    "            \n",
    "  \n",
    "        for index in predicted_indices[0]:\n",
    "            if x[i][index] !=0:\n",
    "                selected_word=reverse_tokenizer.get(x[i][index])\n",
    "                selected_word_index=get_index_word_in_string(selected_word,filtered_split_tweet)\n",
    "                # np.where doesn't work with strings, even if split\n",
    "                #selected_word_index=np.where(filtered_split_tweet==selected_word)\n",
    "                \n",
    "# the commented code is used for debugging  \n",
    "        #        print(i)\n",
    "#                if i==7:\n",
    "#                    print(\"predicted words indices: \",predicted_indices[0])\n",
    "#                    print(\"selected word: \", selected_word)\n",
    "#                    print(\"filtered text: \",filtered_split_tweet)\n",
    "#                    print(\"selected word index:\", selected_word_index)\n",
    "#                    return\n",
    "###################################        \n",
    "                if selected_word_index==-1:\n",
    "                    print(\"there is an error in conversion for tweet row: \",tweets_data_index, \"index number: \",i)\n",
    "                elif len(selected_word_index)==1:                     \n",
    "                    tweet_text_lower_split=tweets_data.text[tweets_data_index].lower().split()\n",
    "                    update=0\n",
    "                    for j in range(len(tweet_text_lower_split)):\n",
    "                        found_word=tweet_text_lower_split[j].find(selected_word)\n",
    "                        if found_word !=-1:\n",
    "                            actual_selected_word=tweets_data.text[tweets_data_index].split()[j]\n",
    "                            duplicate=0\n",
    "                            for k in range(len(actual_selected_words)):\n",
    "                                duplicate_found=get_index_word_in_string(actual_selected_word,actual_selected_words)\n",
    "                                if duplicate_found !=-1:\n",
    "                                    #print(\"duplicate found in row: \",tweets_data_index, \"index number: \",i)\n",
    "                                    duplicate=1\n",
    "                                    update=1\n",
    "                                    break\n",
    "                            if duplicate !=1:\n",
    "                                actual_selected_words.append(actual_selected_word)\n",
    "                                update=1\n",
    "                            break\n",
    "                    if update ==0:\n",
    "                        print(\"error in find for row: \",tweets_data_index, \"index number: \",i)\n",
    "                    #actual_selected_words.append(tweets_data.text[tweets_data_index].split()[selected_word_index[0]])\n",
    "                elif len(selected_word_index)>1:\n",
    "                    ## for now, we chose the word to be of the first index, but should be later updated to be smarter ##\n",
    "                    #actual_selected_words.append(tweets_data.text[tweets_data_index].split()[selected_word_index[0]])\n",
    "                    tweet_text_lower_split=tweets_data.text[tweets_data_index].lower().split()\n",
    "                    update=0\n",
    "                    for j in range(len(tweet_text_lower_split)):\n",
    "                        found_word=tweet_text_lower_split[j].find(selected_word)\n",
    "                        if found_word !=-1:\n",
    "                            actual_selected_word=tweets_data.text[tweets_data_index].split()[j]\n",
    "                            duplicate=0\n",
    "                            for k in range(len(actual_selected_words)):\n",
    "                                duplicate_found=get_index_word_in_string(actual_selected_word,actual_selected_words)\n",
    "                                if duplicate_found !=-1:\n",
    "                                    #print(\"duplicate found in row: \",tweets_data_index, \"index number: \",i)\n",
    "                                    duplicate=1\n",
    "                                    update=1\n",
    "                                    break\n",
    "                            if duplicate !=1:\n",
    "                                actual_selected_words.append(actual_selected_word)\n",
    "                                update=1\n",
    "                            break\n",
    "                    if update ==0:\n",
    "                        print(\"error in find for row: \",tweets_data_index, \"index number: \",i)\n",
    "# the commented code is used for debugging  \n",
    "#        print(i)\n",
    "#            if i==6:\n",
    "#                print(\"predicted words indices: \",predicted_indices[0])\n",
    "#                print(\"selected word: \", selected_word)\n",
    "#                print(\"filtered text: \",filtered_split_tweet)\n",
    "#                print(\"selected word index:\", selected_word_index)\n",
    "#                print(\"actual text split: \",tweets_data.text[tweets_data_index].split())\n",
    "#                return\n",
    "           \n",
    "        actual_selected_text=\" \".join(actual_selected_words)\n",
    "        tweets_data.selected_text[tweets_data_index]=actual_selected_text      \n",
    "        #selected_text=\" \".join(selected_words)    \n",
    "    print(\"total empty selected text: \",no_selected_text)\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def populate_test_selected_text(positive_tweets,negative_tweets,test_data):\n",
    "    for i in tqdm(test_data.index):\n",
    "        if test_data.sentiment[i]==\"neutral\":\n",
    "            test_data.selected_text[i]=test_data.text[i]\n",
    "            \n",
    "        elif test_data.sentiment[i]==\"positive\":\n",
    "            if positive_tweets.textID[i] != test_data.textID[i]:\n",
    "                print(\"There is an error in indices for index: \",i)\n",
    "                for j in positive_tweets.index:\n",
    "                    if positive_tweets.textID[j] == test_data.textID[i]:\n",
    "                        test_data.selected_text[i]=positive_tweets.selected_text[j]\n",
    "                        break\n",
    "            else:\n",
    "                test_data.selected_text[i]=positive_tweets.selected_text[i]\n",
    "                \n",
    "        elif test_data.sentiment[i]==\"negative\":\n",
    "            if negative_tweets.textID[i] != test_data.textID[i]:\n",
    "                print(\"There is an error in indices for index: \",i)\n",
    "                for j in negative_tweets.index:\n",
    "                    if negative_tweets.textID[j] == test_data.textID[i]:\n",
    "                        test_data.selected_text[i]=negative_tweets.selected_text[j]\n",
    "                        break\n",
    "            else:\n",
    "                test_data.selected_text[i]=negative_tweets.selected_text[i]\n",
    "                \n",
    "    return\n",
    "                                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:112: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:32: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total empty selected text:  182\n"
     ]
    }
   ],
   "source": [
    "positive_train_copy1=positive_tweets.copy()\n",
    "convert_pred_index_into_selected_text(positive_x_train,positive_y_test,positive_train_copy1,tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:112: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:32: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total empty selected text:  178\n"
     ]
    }
   ],
   "source": [
    "negative_train_copy1=negative_tweets.copy()\n",
    "convert_pred_index_into_selected_text(negative_x_train,negative_y_test,negative_train_copy1,tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/27480 [00:00<?, ?it/s]/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  after removing the cwd from sys.path.\n",
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:24: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n",
      "100%|██████████| 27480/27480 [00:11<00:00, 2375.24it/s]\n"
     ]
    }
   ],
   "source": [
    "train_copy_copy=train_copy.copy()\n",
    "populate_test_selected_text(positive_train_copy1,negative_train_copy1,train_copy_copy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average jaccard:  0.6670189013222584\n"
     ]
    }
   ],
   "source": [
    "correct_train_copy=train.copy()\n",
    "correct_train_copy.dropna(axis=0, how=\"any\", inplace=True)\n",
    "correct_train_copy.reset_index(inplace=True)\n",
    "\n",
    "jaccard_list=[]\n",
    "for i in correct_train_copy.index:\n",
    "    correct_set=set(correct_train_copy.selected_text[i].split())\n",
    "    predicted_set=set(train_copy_copy.selected_text[i].split())\n",
    "    intersection=correct_set.intersection(predicted_set)\n",
    "    jaccard= float(len(intersection)/(len(correct_set)+len(predicted_set)-len(intersection)))\n",
    "    jaccard_list.append(jaccard)\n",
    "\n",
    "average_jaccard=sum(jaccard_list)/len(jaccard_list)\n",
    "print(\"average jaccard: \", average_jaccard)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total empty selected text:  28\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|█▎        | 472/3534 [00:00<00:00, 4716.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total empty selected text:  24\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3534/3534 [00:00<00:00, 4581.62it/s]\n"
     ]
    }
   ],
   "source": [
    "negative_y_test=negative_model.predict(negative_x_test)\n",
    "negative_y_test=np.around(negative_y_test)\n",
    "negative_test_data_copy=negative_tweets_test.copy()\n",
    "convert_pred_index_into_selected_text(negative_x_test,negative_y_test,negative_test_data_copy,tokenizer)\n",
    "\n",
    "positive_y_test=positive_model.predict(positive_x_test)\n",
    "positive_y_test=np.around(positive_y_test)\n",
    "positive_test_data_copy=positive_tweets_test.copy()\n",
    "convert_pred_index_into_selected_text(positive_x_test,positive_y_test,positive_test_data_copy,tokenizer)\n",
    "test_data_copy=test.copy()\n",
    "populate_test_selected_text(positive_test_data_copy,negative_test_data_copy,test_data_copy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "jaccard score between text and selected text for test set:\n",
      "positive sentiments jaccard score:  0.21959146157147869\n",
      "negative sentiments jaccard score:  0.23278539219454072\n"
     ]
    }
   ],
   "source": [
    "print(\"jaccard score between text and selected text for test set:\")\n",
    "#sentiment jaccard score\n",
    "positive_test_jaccard=get_jaccard(positive_test_data_copy)\n",
    "print(\"positive sentiments jaccard score: \",positive_test_jaccard)\n",
    "negative_test_jaccard=get_jaccard(negative_test_data_copy)\n",
    "print(\"negative sentiments jaccard score: \",negative_test_jaccard)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def csv_submission(test_data):\n",
    "    submission_data={\"textID\":test_data.textID,\n",
    "               \"selected_text\":test_data.selected_text,\n",
    "    }\n",
    "    test_csv=pd.DataFrame(submission_data,columns=[\"textID\",\"selected_text\"])\n",
    "    test_csv.to_csv('submission.csv',index=False)\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_submission(test_data_copy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
